{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a0a57e0",
   "metadata": {},
   "source": [
    "## Điều kiện tiên quyết\n",
    "\n",
    "- GPU NVIDIA (>=12GB được khuyến nghị) cùng bộ driver CUDA hiện hành và bản `torch` tương thích\n",
    "- Python 3.10/3.11 cùng `ffmpeg` trong `PATH` để xử lý âm thanh\n",
    "- Bộ dữ liệu cục bộ chứa các đoạn `.wav` (16 kHz-24 kHz) với một bản chép cho mỗi câu\n",
    "- Đủ dung lượng đĩa để lưu checkpoints/logs trong `outputs/`\n",
    "- (Tùy chọn) Tài khoản Weights & Biases nếu bạn đổi `dashboard_logger`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd89fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT = Path(os.getenv(\"XTTS_PROJECT_ROOT\", Path.cwd())).resolve()\n",
    "DATASET_ROOT = Path(os.getenv(\"XTTS_DATASET_ROOT\", PROJECT_ROOT / \"data\" / \"vi_dataset\")).resolve()\n",
    "TRAIN_METADATA = Path(os.getenv(\"XTTS_TRAIN_META\", DATASET_ROOT / \"metadata_train.csv\"))\n",
    "VAL_METADATA = Path(os.getenv(\"XTTS_VAL_META\", DATASET_ROOT / \"metadata_val.csv\"))\n",
    "OUTPUT_DIR = Path(os.getenv(\"XTTS_OUTPUT_DIR\", PROJECT_ROOT / \"outputs\" / \"xtts_vi_ft\")).resolve()\n",
    "CONFIG_TEMPLATE = Path(os.getenv(\"XTTS_CONFIG_TEMPLATE\", PROJECT_ROOT / \"models\" / \"config.json\")).resolve()\n",
    "CUSTOM_CONFIG = OUTPUT_DIR / \"config.xtts.vi.json\"\n",
    "\n",
    "LANGUAGE = os.getenv(\"XTTS_LANGUAGE\", \"vi\")\n",
    "RUN_NAME = os.getenv(\"XTTS_RUN_NAME\", \"xtts_vi_finetune\")\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Thư mục dự án  : {PROJECT_ROOT}\")\n",
    "print(f\"Thư mục dữ liệu: {DATASET_ROOT}\")\n",
    "print(f\"Manifest train : {TRAIN_METADATA}\")\n",
    "print(f\"Manifest val   : {VAL_METADATA}\")\n",
    "print(f\"Thư mục output : {OUTPUT_DIR}\")\n",
    "print(f\"Tệp config gốc : {CONFIG_TEMPLATE}\")\n",
    "print(f\"Config tùy chỉnh: {CUSTOM_CONFIG}\")\n",
    "print(f\"Mã ngôn ngữ    : {LANGUAGE}\")\n",
    "print(f\"Tên lượt chạy  : {RUN_NAME}\")\n",
    "\n",
    "if not CONFIG_TEMPLATE.exists():\n",
    "    raise FileNotFoundError(f\"Thiếu tệp config gốc: {CONFIG_TEMPLATE}\")\n",
    "if not DATASET_ROOT.exists():\n",
    "    print(\"CẢNH BÁO: DATASET_ROOT chưa tồn tại. Hãy cập nhật XTTS_DATASET_ROOT trước khi huấn luyện.\")\n",
    "if not TRAIN_METADATA.exists():\n",
    "    print(\"THÔNG BÁO: Không tìm thấy TRAIN_METADATA. Hãy tạo manifest bằng cell tương ứng trước khi huấn luyện.\")\n",
    "if not VAL_METADATA.exists():\n",
    "    print(\"THÔNG BÁO: Không tìm thấy VAL_METADATA. Trình huấn luyện sẽ tự chia tập eval.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài đặt phụ thuộc của repo và runtime (chạy một lần cho mỗi môi trường).\n",
    "%pip install --upgrade pip wheel setuptools\n",
    "%pip install -e .\n",
    "%pip install tensorboard pandas soundfile mutagen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f630ff",
   "metadata": {},
   "source": [
    "## Định dạng manifest dữ liệu\n",
    "\n",
    "Các bộ nạp XTTS cần manifest phân tách bằng ký tự `|` để ánh xạ câu thoại và bản chép. Dùng formatter `coqui` dựng sẵn là cách nhanh nhất:\n",
    "```\n",
    "audio_file|text|speaker_name\n",
    "wavs/utt_00001.wav|Xin chào tất cả mọi người.|speaker_0001\n",
    "wavs/utt_00002.wav|Chúc bạn một ngày tốt lành.|speaker_0001\n",
    "```\n",
    "- đặt manifest trong `DATASET_ROOT`\n",
    "- đặt `language` về đúng mã ISO (mặc định ở đây là `vi`)\n",
    "- thư mục theo từng người nói hoặc cột `speaker_name` rõ ràng giúp cân bằng lấy mẫu\n",
    "- bảo đảm tập kiểm định không trùng với manifest huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc18cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import Tuple\n",
    "\n",
    "def build_manifest_from_transcripts(\n",
    "    dataset_root: Path,\n",
    "    manifest_path: Path,\n",
    "    transcript_suffix: str = \".txt\",\n",
    "    speaker_from_parent: bool = True,\n",
    " ) -> Tuple[Path, int]:\n",
    "    \"\"\"Quét các tệp wav và bản chép cùng tên để tạo manifest tương thích `coqui`.\n",
    "\n",
    "    Mỗi tệp wav cần một tệp văn bản có cùng tên gốc.\n",
    "    \"\"\"\n",
    "    dataset_root = Path(dataset_root)\n",
    "    manifest_path = Path(manifest_path)\n",
    "    rows = []\n",
    "    for wav_path in sorted(dataset_root.rglob(\"*.wav\")):\n",
    "        txt_path = wav_path.with_suffix(transcript_suffix)\n",
    "        if not txt_path.exists():\n",
    "            continue\n",
    "        text = txt_path.read_text(encoding=\"utf-8\").strip()\n",
    "        if not text:\n",
    "            continue\n",
    "        speaker_name = wav_path.parent.name if speaker_from_parent else dataset_root.name\n",
    "        rel_wav = wav_path.relative_to(dataset_root)\n",
    "        rows.append([rel_wav.as_posix(), text, speaker_name])\n",
    "    manifest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with manifest_path.open(\"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.writer(f, delimiter=\"|\")\n",
    "        writer.writerow([\"audio_file\", \"text\", \"speaker_name\"])\n",
    "        writer.writerows(rows)\n",
    "    print(f\"Đã ghi {len(rows)} dòng vào {manifest_path}\")\n",
    "    return manifest_path, len(rows)\n",
    "\n",
    "# Ví dụ sử dụng (bỏ comment sau khi đã có dữ liệu):\n",
    "# build_manifest_from_transcripts(DATASET_ROOT, TRAIN_METADATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8695ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from IPython.display import display\n",
    "\n",
    "def describe_manifest(manifest_path: Path, dataset_root: Path, sample_size: int = 5):\n",
    "    manifest_path = Path(manifest_path)\n",
    "    dataset_root = Path(dataset_root)\n",
    "    if not manifest_path.exists():\n",
    "        raise FileNotFoundError(f\"Không tìm thấy manifest: {manifest_path}\")\n",
    "    df = pd.read_csv(manifest_path, sep=\"|\")\n",
    "    display(df.head(min(sample_size, len(df))))\n",
    "    durations = []\n",
    "    max_rows = min(len(df), max(50, sample_size))\n",
    "    for wav_rel in df[\"audio_file\"].head(max_rows):\n",
    "        wav_path = dataset_root / wav_rel\n",
    "        if not wav_path.exists():\n",
    "            continue\n",
    "        with sf.SoundFile(wav_path) as snd:\n",
    "            durations.append(len(snd) / snd.samplerate)\n",
    "    hours = sum(durations) / 3600 if durations else 0.0\n",
    "    speaker_count = df[\"speaker_name\"].nunique() if \"speaker_name\" in df.columns else \"n/a\"\n",
    "    print(f\"Số dòng        : {len(df)}\")\n",
    "    print(f\"Số speaker duy nhất: {speaker_count}\")\n",
    "    print(f\"Giờ audio xem trước: {hours:.2f} (trên {len(durations)} tệp)\")\n",
    "    return df\n",
    "\n",
    "if TRAIN_METADATA.exists():\n",
    "    train_df = describe_manifest(TRAIN_METADATA, DATASET_ROOT)\n",
    "else:\n",
    "    print(\"Thiếu manifest train. Hãy tạo bằng cell xây manifest.\")\n",
    "\n",
    "if VAL_METADATA.exists():\n",
    "    val_df = describe_manifest(VAL_METADATA, DATASET_ROOT)\n",
    "else:\n",
    "    print(\"Sử dụng chia eval tự động (không có VAL_METADATA).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db2c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "\n",
    "def stage_manifest(manifest_path: Path) -> str:\n",
    "    manifest_path = Path(manifest_path)\n",
    "    if not manifest_path.exists():\n",
    "        raise FileNotFoundError(f\"Không tìm thấy manifest: {manifest_path}\")\n",
    "    target = DATASET_ROOT / manifest_path.name\n",
    "    if manifest_path.resolve() != target.resolve():\n",
    "        target.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(manifest_path, target)\n",
    "        print(f\"Đã sao chép {manifest_path} -> {target}\")\n",
    "    return target.name\n",
    "\n",
    "train_meta_name = stage_manifest(TRAIN_METADATA)\n",
    "val_meta_name = stage_manifest(VAL_METADATA) if VAL_METADATA.exists() else \"\"\n",
    "\n",
    "with CONFIG_TEMPLATE.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    template = json.load(f)\n",
    "\n",
    "config = deepcopy(template)\n",
    "if not config.get(\"datasets\"):\n",
    "    config[\"datasets\"] = [{}]\n",
    "\n",
    "config[\"run_name\"] = RUN_NAME\n",
    "config[\"run_description\"] = f\"{RUN_NAME} ({datetime.utcnow().isoformat()}Z)\"\n",
    "config[\"output_path\"] = str(OUTPUT_DIR)\n",
    "config[\"dashboard_logger\"] = os.getenv(\"XTTS_LOGGER\", config.get(\"dashboard_logger\", \"tensorboard\"))\n",
    "config[\"epochs\"] = int(os.getenv(\"XTTS_EPOCHS\", config.get(\"epochs\", 5)))\n",
    "config[\"batch_size\"] = int(os.getenv(\"XTTS_BATCH_SIZE\", config.get(\"batch_size\", 2)))\n",
    "config[\"eval_batch_size\"] = int(os.getenv(\"XTTS_EVAL_BATCH_SIZE\", config.get(\"eval_batch_size\", config.get(\"batch_size\", 2))))\n",
    "config[\"lr\"] = float(os.getenv(\"XTTS_LR\", config.get(\"lr\", 5e-6)))\n",
    "config[\"mixed_precision\"] = os.getenv(\"XTTS_MIXED_PRECISION\", str(config.get(\"mixed_precision\", False))).lower() == \"true\"\n",
    "\n",
    "dataset_cfg = config[\"datasets\"][0]\n",
    "dataset_cfg[\"formatter\"] = dataset_cfg.get(\"formatter\") or \"coqui\"\n",
    "dataset_cfg[\"dataset_name\"] = RUN_NAME\n",
    "dataset_cfg[\"path\"] = str(DATASET_ROOT)\n",
    "dataset_cfg[\"meta_file_train\"] = train_meta_name\n",
    "dataset_cfg[\"meta_file_val\"] = val_meta_name\n",
    "dataset_cfg[\"language\"] = LANGUAGE\n",
    "dataset_cfg[\"phonemizer\"] = dataset_cfg.get(\"phonemizer\", \"\")\n",
    "dataset_cfg[\"ignored_speakers\"] = None\n",
    "dataset_cfg[\"meta_file_attn_mask\"] = dataset_cfg.get(\"meta_file_attn_mask\", \"\")\n",
    "config[\"datasets\"][0] = dataset_cfg\n",
    "\n",
    "with CUSTOM_CONFIG.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"Đã ghi config tùy chỉnh vào {CUSTOM_CONFIG}\")\n",
    "print(f\"Formatter dữ liệu : {dataset_cfg['formatter']}\")\n",
    "print(f\"Đường dẫn train   : {dataset_cfg['path']}/{dataset_cfg['meta_file_train']}\")\n",
    "print(f\"Đường dẫn eval    : {dataset_cfg['path']}/{dataset_cfg['meta_file_val'] or 'tự chia'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b2bc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.config import load_config\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "\n",
    "cfg = load_config(str(CUSTOM_CONFIG))\n",
    "train_samples, eval_samples = load_tts_samples(\n",
    "    cfg.datasets,\n",
    "    eval_split=cfg.run_eval,\n",
    "    eval_split_max_size=cfg.eval_split_max_size,\n",
    "    eval_split_size=cfg.eval_split_size,\n",
    "    )\n",
    "\n",
    "print(f\"Số mẫu train : {len(train_samples)}\")\n",
    "print(f\"Số mẫu eval  : {len(eval_samples) if eval_samples is not None else 0}\")\n",
    "if train_samples:\n",
    "    preview = train_samples[0]\n",
    "    print(\"Các khóa ví dụ:\", list(preview.keys()))\n",
    "    print(\"Trích đoạn văn bản:\", preview['text'][:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ac5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shlex\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "train_script = PROJECT_ROOT / \"TTS\" / \"bin\" / \"train_tts.py\"\n",
    "continue_path = os.getenv(\"XTTS_CONTINUE_PATH\")\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    str(train_script),\n",
    "    \"--config_path\",\n",
    "    str(CUSTOM_CONFIG),\n",
    "]\n",
    "if continue_path:\n",
    "    cmd += [\"--continue_path\", continue_path]\n",
    "\n",
    "print(\"Lệnh huấn luyện:\")\n",
    "print(\" \".join(shlex.quote(str(token)) for token in cmd))\n",
    "\n",
    "LAUNCH_TRAINING = False  # Đặt True để chạy trực tiếp trong notebook.\n",
    "if LAUNCH_TRAINING:\n",
    "    process = subprocess.run(cmd, cwd=PROJECT_ROOT, check=False)\n",
    "    print(f\"Tiến trình huấn luyện kết thúc với mã {process.returncode}\")\n",
    "else:\n",
    "    print(\"Chế độ mô phỏng (dry-run). Chuyển LAUNCH_TRAINING sang True khi bạn sẵn sàng.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c5ded5",
   "metadata": {},
   "source": [
    "## Theo dõi & tiếp tục\n",
    "\n",
    "- Đặt `XTTS_CONTINUE_PATH` tới thư mục checkpoint (`output/<run_name>`) để khôi phục phiên huấn luyện bị gián đoạn.\n",
    "- Dùng TensorBoard để quan sát loss, gradient, attention và bản xem trước audio.\n",
    "- Nếu bật logging Weights & Biases, đặt `dashboard_logger` = `wandb` và khai báo `WANDB_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e7d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mở TensorBoard ngay trong notebook (dừng cell để giải phóng cổng).\n",
    "logdir = OUTPUT_DIR.as_posix()\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {logdir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dede13",
   "metadata": {},
   "source": [
    "## Suy luận hậu huấn luyện\n",
    "\n",
    "Chỉ định checkpoint đã huấn luyện (thường là `best_model.pth` hoặc `checkpoint_<step>.pth`) và cung cấp tệp tham chiếu giọng nói để clone. File demo sẽ được lưu cạnh thư mục kết quả của lượt chạy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from TTS.api import TTS as CoquiTTS\n",
    "\n",
    "checkpoint_override = os.getenv(\"XTTS_CHECKPOINT\")\n",
    "if checkpoint_override:\n",
    "    checkpoint_path = Path(checkpoint_override)\n",
    "else:\n",
    "    candidates = sorted(OUTPUT_DIR.glob(\"best_model*.pth\")) or sorted(OUTPUT_DIR.glob(\"checkpoint_*model.pth\"))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\"Không tìm thấy checkpoint trong OUTPUT_DIR.\")\n",
    "    checkpoint_path = candidates[-1]\n",
    "\n",
    "speaker_ref = Path(os.getenv(\"XTTS_SPEAKER_REF\", \"\"))\n",
    "if speaker_ref and speaker_ref.exists():\n",
    "    speaker_wav = str(speaker_ref)\n",
    "else:\n",
    "    speaker_wav = None\n",
    "\n",
    "sample_text = os.getenv(\"XTTS_TEST_SENTENCE\", \"Xin chào, đây là bản kiểm thử XTTS sau khi fine-tune.\")\n",
    "output_wav = OUTPUT_DIR / \"sample_inference.wav\"\n",
    "\n",
    "tts_model = CoquiTTS(\n",
    "    model_path=str(checkpoint_path),\n",
    "    config_path=str(CUSTOM_CONFIG),\n",
    "    progress_bar=False,\n",
    "    gpu=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "tts_model.tts_to_file(\n",
    "    text=sample_text,\n",
    "    speaker_wav=speaker_wav,\n",
    "    language=LANGUAGE,\n",
    "    file_path=str(output_wav),\n",
    ")\n",
    "print(f\"Đã lưu audio demo tại {output_wav}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
