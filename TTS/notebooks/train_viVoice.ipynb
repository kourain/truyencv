{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q datasets huggingface_hub pandas librosa soundfile mutagen tqdm coqpit trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47514235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bảo đảm import được gói TTS local trong repo\n",
    "import sys, os\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if os.path.exists(os.path.join(repo_root, \"TTS\")) and repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "print(\"Repo root:\", repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd50972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv(os.path.join(repo_root, \".env\"))\n",
    "from huggingface_hub import login\n",
    "token = os.environ.get(\"HF_TOKEN\", \"\")\n",
    "if not token:\n",
    "    raise RuntimeError(\"Set HF_TOKEN env var with a valid Hugging Face token that has access to capleaf/viVoice.\")\n",
    "login(token=token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "DATASET_NAME = \"capleaf/viVoice\"\n",
    "OUTPUT_ROOT = Path(\"data/viVoice\").as_posix()\n",
    "WAVS_DIR = os.path.join(OUTPUT_ROOT, \"wavs\")\n",
    "META_FILE = \"meta_train.csv\"\n",
    "SAMPLE_RATE = 24000\n",
    "MAX_SAMPLES =  None #2000  # set None to use all\n",
    "\n",
    "os.makedirs(WAVS_DIR, exist_ok=True)\n",
    "print(OUTPUT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa, soundfile as sf\n",
    "import tqdm, os\n",
    "\n",
    "ds = load_dataset(DATASET_NAME, split=\"train\", streaming=True)\n",
    "rows = []\n",
    "count = 0\n",
    "\n",
    "def _get_text(ex):\n",
    "    return ex.get(\"text\") or ex.get(\"sentence\") or ex.get(\"transcript\") or ex.get(\"transcription\") or ex.get(\"normalized_text\")\n",
    "\n",
    "def _get_speaker(ex):\n",
    "    return ex.get(\"speaker\") or ex.get(\"speaker_id\") or ex.get(\"channel_id\") or ex.get(\"channel\") or \"vivoice\"\n",
    "\n",
    "for ex in tqdm.tqdm(ds, total=MAX_SAMPLES if MAX_SAMPLES else None):\n",
    "    text = _get_text(ex)\n",
    "    if not text:\n",
    "        continue\n",
    "    spk = _get_speaker(ex)\n",
    "\n",
    "    audio = ex.get(\"audio\") or ex.get(\"audio_raw\") or ex.get(\"audio_data\")\n",
    "    wav_path = os.path.join(WAVS_DIR, f\"{count:09d}.wav\")\n",
    "    if isinstance(audio, dict) and \"array\" in audio:\n",
    "        y = np.asarray(audio[\"array\"], dtype=np.float32)\n",
    "        sr = audio.get(\"sampling_rate\") or SAMPLE_RATE\n",
    "    else:\n",
    "        p = ex.get(\"path\") or ex.get(\"audio_filepath\") or ex.get(\"audio_file\") or ex.get(\"wav\")\n",
    "        if not p:\n",
    "            continue\n",
    "        y, sr = librosa.load(p, sr=None, mono=True)\n",
    "    if sr != SAMPLE_RATE:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=SAMPLE_RATE)\n",
    "        sr = SAMPLE_RATE\n",
    "    sf.write(wav_path, y, int(sr))\n",
    "    rows.append({\"audio_file\": f\"wavs/{os.path.basename(wav_path)}\", \"text\": str(text), \"speaker_name\": str(spk)})\n",
    "    count += 1\n",
    "    if MAX_SAMPLES and count >= MAX_SAMPLES:\n",
    "        break\n",
    "\n",
    "meta_path = os.path.join(OUTPUT_ROOT, META_FILE)\n",
    "pd.DataFrame(rows, columns=[\"audio_file\",\"text\",\"speaker_name\"]).to_csv(meta_path, sep=\"|\", index=False)\n",
    "meta_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.tts.configs.vits_config import VitsConfig\n",
    "from TTS.config.shared_configs import BaseDatasetConfig\n",
    "\n",
    "cfg = VitsConfig()\n",
    "cfg.audio.sample_rate = 24000\n",
    "cfg.output_path = \"outputs/vivoice_vits\"\n",
    "cfg.datasets = [BaseDatasetConfig(\n",
    "    formatter=\"coqui\",\n",
    "    dataset_name=\"vivoice\",\n",
    "    path=OUTPUT_ROOT,\n",
    "    meta_file_train=META_FILE,\n",
    "    meta_file_val=\"\",\n",
    "    language=\"vi\",\n",
    ")]\n",
    "cfg.use_phonemes = False\n",
    "cfg.add_blank = True\n",
    "cfg.model_args.use_speaker_embedding = True\n",
    "cfg.num_loader_workers = 2\n",
    "cfg.num_eval_loader_workers = 2\n",
    "cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer, TrainerArgs\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.models import setup_model\n",
    "\n",
    "train_samples, eval_samples = load_tts_samples(\n",
    "    cfg.datasets, eval_split=True, eval_split_max_size=cfg.eval_split_max_size, eval_split_size=cfg.eval_split_size\n",
    ")\n",
    "model = setup_model(cfg, train_samples + eval_samples)\n",
    "\n",
    "train_args = TrainerArgs()\n",
    "trainer = Trainer(\n",
    "    train_args,\n",
    "    model.config,\n",
    "    cfg.output_path,\n",
    "    model=model,\n",
    "    train_samples=train_samples,\n",
    "    eval_samples=eval_samples,\n",
    "    parse_command_line_args=False,\n",
    ")\n",
    "trainer.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "import json, os\n",
    "os.makedirs(cfg.output_path, exist_ok=True)\n",
    "with open(os.path.join(cfg.output_path, \"config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(asdict(cfg), f, ensure_ascii=False, indent=2)\n",
    "os.path.join(cfg.output_path, \"config.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
