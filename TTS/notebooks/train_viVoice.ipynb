{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q datasets huggingface_hub pandas librosa soundfile mutagen tqdm coqpit trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47514235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bảo đảm import được gói TTS local trong repo\n",
    "import sys, os\n",
    "\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if os.path.exists(os.path.join(repo_root, \"TTS\")) and repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "print(\"Repo root:\", repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd50972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(os.path.join(repo_root, \".env\"))\n",
    "from huggingface_hub import login\n",
    "\n",
    "token = os.environ.get(\"HF_TOKEN\", \"\")\n",
    "if not token:\n",
    "    raise RuntimeError(\n",
    "        \"Set HF_TOKEN env var with a valid Hugging Face token that has access to capleaf/viVoice.\"\n",
    "    )\n",
    "login(token=token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef5e178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "DATASET_NAME = \"capleaf/viVoice\"\n",
    "OUTPUT_ROOT = Path(\"data/viVoice\").as_posix()\n",
    "WAVS_DIR = os.path.join(OUTPUT_ROOT, \"wavs\")\n",
    "META_FILE = \"metadata.csv\"\n",
    "META_TRAIN_FILE = \"meta_train.csv\"\n",
    "META_EVAL_FILE = \"meta_eval.csv\"\n",
    "SAMPLE_RATE = 24000\n",
    "MAX_SAMPLES = None  # đặt số nhỏ (vd 50000) nếu không muốn tải toàn bộ viVoice\n",
    "EVAL_SPLIT = 0.02  # 2% làm validation\n",
    "\n",
    "os.makedirs(WAVS_DIR, exist_ok=True)\n",
    "print(\"Output root:\", OUTPUT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb443e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa, soundfile as sf\n",
    "import tqdm, os\n",
    "\n",
    "# Cell 4: Tải dataset viVoice (streaming) và lưu về định dạng coqui: audio_file|text|speaker_name\n",
    "# - Streaming để không tải toàn bộ về RAM cùng lúc (viVoice rất lớn)\n",
    "# - Resample tất cả về 24kHz (SAMPLE_RATE) để đồng bộ với XTTS (XTTS dùng 24kHz)\n",
    "# - Tách ngẫu nhiên thành train/eval theo EVAL_SPLIT (2% làm validation)\n",
    "# - Ghi ra một file meta duy nhất (metadata.csv) theo định dạng coqui\n",
    "\n",
    "ds = load_dataset(DATASET_NAME, split=\"train\", streaming=True)\n",
    "rows = []  # chỉ dùng một list, không tách train/eval ở đây\n",
    "count = 0\n",
    "\n",
    "\n",
    "def _get_text(ex):\n",
    "    \"\"\"Trích trường text từ một mẫu dataset (tên trường có thể khác nhau giữa các dataset).\"\"\"\n",
    "    return (\n",
    "        ex.get(\"text\")\n",
    "        or ex.get(\"sentence\")\n",
    "        or ex.get(\"transcript\")\n",
    "        or ex.get(\"transcription\")\n",
    "        or ex.get(\"normalized_text\")\n",
    "    )\n",
    "\n",
    "\n",
    "def _get_speaker(ex):\n",
    "    \"\"\"Trích trường speaker_id/channel, nếu không có thì mặc định 'vivoice'.\"\"\"\n",
    "    return (\n",
    "        ex.get(\"speaker\")\n",
    "        or ex.get(\"speaker_id\")\n",
    "        or ex.get(\"channel_id\")\n",
    "        or ex.get(\"channel\")\n",
    "        or \"vivoice\"\n",
    "    )\n",
    "\n",
    "\n",
    "for ex in tqdm.tqdm(ds, total=MAX_SAMPLES if MAX_SAMPLES else None):\n",
    "    text = _get_text(ex)\n",
    "    if not text:\n",
    "        continue\n",
    "    spk = _get_speaker(ex)\n",
    "\n",
    "    # Lấy audio: có thể là dict với array hoặc path file\n",
    "    audio = ex.get(\"audio\") or ex.get(\"audio_raw\") or ex.get(\"audio_data\")\n",
    "    wav_path = os.path.join(WAVS_DIR, f\"{count:09d}.wav\")\n",
    "    if isinstance(audio, dict) and \"array\" in audio:\n",
    "        y = np.asarray(audio[\"array\"], dtype=np.float32)\n",
    "        sr = audio.get(\"sampling_rate\") or SAMPLE_RATE\n",
    "    else:\n",
    "        p = (\n",
    "            ex.get(\"path\")\n",
    "            or ex.get(\"audio_filepath\")\n",
    "            or ex.get(\"audio_file\")\n",
    "            or ex.get(\"wav\")\n",
    "        )\n",
    "        if not p:\n",
    "            continue\n",
    "        y, sr = librosa.load(p, sr=None, mono=True)\n",
    "    # Resample về 24kHz nếu cần (XTTS dùng 24kHz)\n",
    "    if sr != SAMPLE_RATE:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=SAMPLE_RATE)\n",
    "        sr = SAMPLE_RATE\n",
    "    sf.write(wav_path, y, int(sr))\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"audio_file\": f\"wavs/{os.path.basename(wav_path)}\",\n",
    "            \"text\": str(text),\n",
    "            \"speaker_name\": str(spk),\n",
    "        }\n",
    "    )\n",
    "    count += 1\n",
    "    if MAX_SAMPLES and count >= MAX_SAMPLES:\n",
    "        break\n",
    "\n",
    "# Ghi ra một file CSV theo định dạng coqui: audio_file|text|speaker_name\n",
    "# Trainer sẽ tự tách train/eval nếu cần\n",
    "meta_path = os.path.join(OUTPUT_ROOT, META_FILE)\n",
    "pd.DataFrame(rows, columns=[\"audio_file\", \"text\", \"speaker_name\"]).to_csv(\n",
    "    meta_path, sep=\"|\", index=False\n",
    ")\n",
    "meta_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe22d8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.tts.configs.vits_config import VitsConfig\n",
    "from TTS.config.shared_configs import BaseDatasetConfig\n",
    "\n",
    "# Cell 5: Cấu hình VITS (giữ lại nếu bạn muốn thử VITS trước khi chuyển XTTS)\n",
    "# - Nếu bạn muốn fine-tune XTTS, hãy bỏ qua cell này và chạy cell XTTS ở dưới\n",
    "# - Nếu bạn muốn train VITS, giữ lại và chạy cell 6–7\n",
    "\n",
    "cfg = VitsConfig()\n",
    "cfg.audio.sample_rate = 24000\n",
    "cfg.output_path = \"train/vivoice_vits\"\n",
    "cfg.datasets = [\n",
    "    BaseDatasetConfig(\n",
    "        formatter=\"coqui\",\n",
    "        dataset_name=\"vivoice\",\n",
    "        path=OUTPUT_ROOT,\n",
    "        meta_file_train=META_FILE,  # dùng metadata.csv đã tạo ở cell 4\n",
    "        meta_file_val=\"\",\n",
    "        language=\"vi\",\n",
    "    )\n",
    "]\n",
    "cfg.use_phonemes = False\n",
    "cfg.add_blank = True\n",
    "cfg.model_args.use_speaker_embedding = True\n",
    "cfg.num_loader_workers = 2\n",
    "cfg.num_eval_loader_workers = 2\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef357706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer, TrainerArgs\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.models import setup_model\n",
    "\n",
    "# Cell 6: Train VITS (chỉ chạy nếu bạn muốn train VITS)\n",
    "# - load_tts_samples sẽ tự động tách train/eval theo cfg.eval_split_size\n",
    "# - setup_model khởi tạo VITS từ cfg\n",
    "# - Trainer bắt đầu fit\n",
    "\n",
    "train_samples, eval_samples = load_tts_samples(\n",
    "    cfg.datasets,\n",
    "    eval_split=True,\n",
    "    eval_split_max_size=cfg.eval_split_max_size,\n",
    "    eval_split_size=cfg.eval_split_size,\n",
    ")\n",
    "model = setup_model(cfg, train_samples + eval_samples)\n",
    "\n",
    "train_args = TrainerArgs()\n",
    "trainer = Trainer(\n",
    "    train_args,\n",
    "    model.config,\n",
    "    cfg.output_path,\n",
    "    model=model,\n",
    "    train_samples=train_samples,\n",
    "    eval_samples=eval_samples,\n",
    "    parse_command_line_args=False,\n",
    ")\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a7b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "import json, os\n",
    "\n",
    "# Cell 7: Lưu config VITS ra file JSON (để inference sau này)\n",
    "# - Ghi cfg vào outputs/vivoice_vits/config.json\n",
    "# - Có thể dùng để load model lại bằng VitsConfig.from_json(...)\n",
    "\n",
    "os.makedirs(cfg.output_path, exist_ok=True)\n",
    "with open(os.path.join(cfg.output_path, \"config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(asdict(cfg), f, ensure_ascii=False, indent=2)\n",
    "os.path.join(cfg.output_path, \"config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a03359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PHẦN FINE-TUNE XTTS ===\n",
    "# Nếu bạn muốn fine-tune XTTS thay vì VITS, hãy chạy các cell từ đây trở xuống\n",
    "\n",
    "# Cell 8 (nếu cần): Kiểm tra lại đường dẫn file metadata.csv đã tạo ở cell 4\n",
    "import os\n",
    "print(\"Metadata CSV:\", os.path.join(OUTPUT_ROOT, META_FILE))\n",
    "print(\"Số mẫu:\", len(pd.read_csv(os.path.join(OUTPUT_ROOT, META_FILE), sep=\"|\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f73c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.demos.xtts_ft_demo.utils.gpt_train import train_gpt\n",
    "\n",
    "# Cell 9: Cấu hình fine-tune XTTS trên viVoice\n",
    "# - LANGUAGE: ngôn ngữ của dataset (vi cho tiếng Việt)\n",
    "# - NUM_EPOCHS: số epoch train, tăng lên 20–50 cho train dài\n",
    "# - BATCH_SIZE: batch size cho mỗi step; 4 an toàn hơn cho GPU 12–16GB\n",
    "# - GRAD_ACUMM: gradient accumulation, giúp effective batch = BATCH_SIZE * GRAD_ACUMM\n",
    "# - MAX_AUDIO_SECONDS: độ dài audio tối đa mỗi mẫu (giữ 20s để dùng nhiều dữ liệu dài hơn)\n",
    "# - TRAIN_CSV_PATH / EVAL_CSV_PATH: cùng trỏ vào metadata.csv (train_gpt sẽ tự tách)\n",
    "# - OUTPUT_XTTS_ROOT: thư mục chứa checkpoint và log của XTTS fine-tune\n",
    "\n",
    "LANGUAGE = \"vi\"\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 4\n",
    "GRAD_ACUMM = 2\n",
    "MAX_AUDIO_SECONDS = 20\n",
    "\n",
    "TRAIN_CSV_PATH = os.path.join(OUTPUT_ROOT, META_FILE)  # dùng chung metadata.csv\n",
    "EVAL_CSV_PATH = os.path.join(OUTPUT_ROOT, META_FILE)    # train_gpt sẽ tự tách\n",
    "OUTPUT_XTTS_ROOT = \"outputs/vivoice_xtts\"\n",
    "\n",
    "print(\"Train CSV:\", TRAIN_CSV_PATH)\n",
    "print(\"Eval  CSV:\", EVAL_CSV_PATH)\n",
    "print(\"Output :\", OUTPUT_XTTS_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30a25a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Chạy fine-tune XTTS GPT trên viVoice\n",
    "# - train_gpt() sẽ tự động:\n",
    "#   1. Tải các pre‑trained model XTTS (dvae, mel_stats, vocab, model.pth, config.json)\n",
    "#   2. Tạo GPTTrainerConfig với batch_size, grad_accum, num_loader_workers, ...\n",
    "#   3. Tạo dataset từ CSV theo formatter \"coqui\"\n",
    "#   4. Khởi tạo GPTTrainer và bắt đầu fine‑tune GPT của XTTS\n",
    "# - Trả về:\n",
    "#   - config_path: config XTTS gốc (để inference)\n",
    "#   - xtts_checkpoint: model XTTS gốc (để inference)\n",
    "#   - vocab_file: vocab tokenizer\n",
    "#   - exp_path: thư mục run chứa checkpoint fine‑tuned (best_model.pth)\n",
    "#   - speaker_ref: file wav dài nhất dùng làm reference khi inference\n",
    "\n",
    "config_path, xtts_checkpoint, vocab_file, exp_path, speaker_ref = train_gpt(\n",
    "    LANGUAGE,\n",
    "    NUM_EPOCHS,\n",
    "    BATCH_SIZE,\n",
    "    GRAD_ACUMM,\n",
    "    TRAIN_CSV_PATH,\n",
    "    EVAL_CSV_PATH,\n",
    "    output_path=OUTPUT_XTTS_ROOT,\n",
    "    max_audio_length=int(MAX_AUDIO_SECONDS * 22050),\n",
    ")\n",
    "\n",
    "print(\"XTTS config :\", config_path)\n",
    "print(\"XTTS ckpt   :\", xtts_checkpoint)\n",
    "print(\"Vocab file  :\", vocab_file)\n",
    "print(\"Run folder  :\", exp_path)\n",
    "print(\"Speaker ref :\", speaker_ref)\n",
    "\n",
    "config_path, xtts_checkpoint, vocab_file, exp_path, speaker_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dc34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11 (tùy chọn): Inference thử với XTTS đã fine‑tune\n",
    "# - Dùng config_path, xtts_checkpoint, vocab_file, exp_path từ cell 10\n",
    "# - speaker_ref là file wav dùng làm giọng tham chiếu\n",
    "# - Ví dụ:\n",
    "#   from TTS.tts.configs.xtts_config import XttsConfig\n",
    "#   from TTS.tts.models.xtts import Xtts\n",
    "#   import soundfile as sf\n",
    "#\n",
    "#   cfg = XttsConfig()\n",
    "#   cfg.load_json(config_path)\n",
    "#   model = Xtts.init_from_config(cfg)\n",
    "#   model.load_checkpoint(cfg, checkpoint_path=os.path.join(exp_path, \"best_model.pth\"), vocab_path=vocab_file)\n",
    "#   model.cuda()\n",
    "#\n",
    "#   text = \"Xin chào, đây là thử nghiệm giọng nói tiếng Việt.\"\n",
    "#   wav = model.full_inference(text, speaker_ref, language=\"vi\")[\"wav\"]\n",
    "#   sf.write(\"out.wav\", wav, 24000)\n",
    "#\n",
    "# # Bỏ comment để chạy khi đã có checkpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
